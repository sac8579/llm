{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlu-s2k9D1Ba"
      },
      "source": [
        "### Homework 5 (10pt): Question search engine\n",
        "\n",
        "Remeber Week01, where you used GloVe embeddings to find related questions? That was... cute. Now, it's time to really solve this task using context-aware embeddings.\n",
        "\n",
        "__Warning:__ this task assumes you have seen `practice06.ipynb` [notebook](https://github.com/anton-selitskiy/RIT_LLM/blob/main/Week06_bert/practice06.ipynb)\n",
        "\n",
        "This assignmend is inspired by this [notebook](https://github.com/yandexdataschool/nlp_course/blob/2024/week05_transfer/homework.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T23:32:24.677572Z",
          "iopub.status.busy": "2025-02-18T23:32:24.677259Z",
          "iopub.status.idle": "2025-02-18T23:32:32.330860Z",
          "shell.execute_reply": "2025-02-18T23:32:32.330184Z",
          "shell.execute_reply.started": "2025-02-18T23:32:24.677544Z"
        },
        "id": "HYffoHiI8du5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#%pip install --upgrade transformers datasets accelerate deepspeed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "import datasets\n",
        "import os\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfSHyQlT-fVF"
      },
      "source": [
        "### Load data and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T23:32:32.332114Z",
          "iopub.status.busy": "2025-02-18T23:32:32.331770Z",
          "iopub.status.idle": "2025-02-18T23:32:37.538516Z",
          "shell.execute_reply": "2025-02-18T23:32:37.537884Z",
          "shell.execute_reply.started": "2025-02-18T23:32:32.332094Z"
        },
        "id": "Y2_wgtrx8e6C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "qqp = datasets.load_dataset('SetFit/qqp')\n",
        "print('\\n')\n",
        "print(\"Sample[0]:\", qqp['train'][0])\n",
        "print(\"Sample[3]:\", qqp['train'][3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T19:38:21.326646Z",
          "iopub.status.busy": "2025-02-18T19:38:21.326118Z",
          "iopub.status.idle": "2025-02-18T19:38:41.323030Z",
          "shell.execute_reply": "2025-02-18T19:38:41.321612Z",
          "shell.execute_reply.started": "2025-02-18T19:38:21.326615Z"
        },
        "id": "pStlWcvD8rdk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_name = \"gchhablani/bert-base-cased-finetuned-qqp\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM3ZujeZ-Z7E"
      },
      "source": [
        "### Tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T19:38:49.442588Z",
          "iopub.status.busy": "2025-02-18T19:38:49.441562Z",
          "iopub.status.idle": "2025-02-18T19:40:24.278815Z",
          "shell.execute_reply": "2025-02-18T19:40:24.278038Z",
          "shell.execute_reply.started": "2025-02-18T19:38:49.442558Z"
        },
        "id": "qtkllSPG9bTL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 128\n",
        "def preprocess_function(examples):\n",
        "    result = tokenizer(\n",
        "        examples['text1'], examples['text2'],\n",
        "        padding='max_length', max_length=MAX_LENGTH, truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    result['label'] = torch.tensor(examples['label'], dtype=torch.long)\n",
        "    return result\n",
        "\n",
        "qqp_preprocessed = {\n",
        "    split: [preprocess_function(sample) for sample in qqp[split]] for split in ['train', 'validation', 'test']\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T19:40:24.280305Z",
          "iopub.status.busy": "2025-02-18T19:40:24.279984Z",
          "iopub.status.idle": "2025-02-18T19:40:24.287423Z",
          "shell.execute_reply": "2025-02-18T19:40:24.286529Z",
          "shell.execute_reply.started": "2025-02-18T19:40:24.280270Z"
        },
        "id": "ObMcFN59_Ll2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(repr(qqp_preprocessed['train'][0]['input_ids'])[:100], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T19:40:24.289075Z",
          "iopub.status.busy": "2025-02-18T19:40:24.288839Z",
          "iopub.status.idle": "2025-02-18T19:40:24.658139Z",
          "shell.execute_reply": "2025-02-18T19:40:24.657150Z",
          "shell.execute_reply.started": "2025-02-18T19:40:24.289054Z"
        },
        "id": "OV0i_trzGxLA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(qqp_preprocessed['train'][0][\"input_ids\"].squeeze(0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyQ1ZbzGAUF2"
      },
      "source": [
        "### Task 1: evaluation (3 point)\n",
        "\n",
        "We randomly chose a model trained on QQP - but is it any good?\n",
        "\n",
        "One way to assess this is by measuring validation accuracy, which you will implement next.\n",
        "\n",
        "Hereâ€™s the interface to help you get started:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T23:32:13.981563Z",
          "iopub.status.busy": "2025-02-18T23:32:13.981271Z",
          "iopub.status.idle": "2025-02-18T23:32:13.990865Z",
          "shell.execute_reply": "2025-02-18T23:32:13.989774Z",
          "shell.execute_reply.started": "2025-02-18T23:32:13.981538Z"
        },
        "id": "M5ueSoieAbBg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class QQPDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return {\n",
        "            \"input_ids\": item[\"input_ids\"].squeeze(0),  # Remove batch dim\n",
        "            \"attention_mask\": item[\"attention_mask\"].squeeze(0),\n",
        "            \"token_type_ids\": item[\"token_type_ids\"].squeeze(0),\n",
        "            \"labels\": item[\"label\"]\n",
        "        }\n",
        "\n",
        "val_set = QQPDataset(qqp_preprocessed['validation'])\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=32, shuffle=False, collate_fn=transformers.default_data_collator, num_workers=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T19:40:36.760770Z",
          "iopub.status.busy": "2025-02-18T19:40:36.760446Z",
          "iopub.status.idle": "2025-02-18T19:40:51.373736Z",
          "shell.execute_reply": "2025-02-18T19:40:51.372727Z",
          "shell.execute_reply.started": "2025-02-18T19:40:36.760747Z"
        },
        "id": "SsPwXXx-At-i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "for batch in val_loader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to GPU\n",
        "    break  # Read one batch only\n",
        "print(\"Sample batch:\", batch)\n",
        "\n",
        "with torch.no_grad():\n",
        "    predicted = model(\n",
        "        input_ids=batch['input_ids'],\n",
        "        attention_mask=batch['attention_mask'],\n",
        "        token_type_ids=batch['token_type_ids']\n",
        "    )\n",
        "\n",
        "print('\\nPrediction (probs):', torch.softmax(predicted.logits, dim=1).cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoxHzxn0DQqO"
      },
      "source": [
        "__Your task__ is to measure the validation accuracy of your model.\n",
        "Doing so naively may take several hours. Please make sure you use the following optimizations:\n",
        "\n",
        "- run the model on GPU with no_grad\n",
        "- using batch size larger than 1\n",
        "- use optimize data loader with num_workers > 1\n",
        "- (optional) use [mixed precision](https://pytorch.org/docs/stable/notes/amp_examples.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T23:33:03.019619Z",
          "iopub.status.busy": "2025-02-18T23:33:03.019153Z",
          "iopub.status.idle": "2025-02-18T23:33:03.023118Z",
          "shell.execute_reply": "2025-02-18T23:33:03.022433Z",
          "shell.execute_reply.started": "2025-02-18T23:33:03.019595Z"
        },
        "id": "3dodymkdGxLA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T05:16:03.757300Z",
          "iopub.status.busy": "2025-02-18T05:16:03.757052Z",
          "iopub.status.idle": "2025-02-18T05:16:03.762556Z",
          "shell.execute_reply": "2025-02-18T05:16:03.761476Z",
          "shell.execute_reply.started": "2025-02-18T05:16:03.757278Z"
        },
        "id": "9k5EK7-KA5F2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        # Move batch to GPU\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch.get('token_type_ids', None)\n",
        "        )\n",
        "\n",
        "        # Predictions\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        predictions = torch.argmax(probs, dim=1)\n",
        "\n",
        "        # Compute accuracy\n",
        "        correct += (predictions == batch['labels']).sum().item()\n",
        "        total += batch['labels'].size(0)\n",
        "\n",
        "accuracy = correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T05:16:16.518197Z",
          "iopub.status.busy": "2025-02-18T05:16:16.517878Z",
          "iopub.status.idle": "2025-02-18T05:16:16.522121Z",
          "shell.execute_reply": "2025-02-18T05:16:16.521334Z",
          "shell.execute_reply.started": "2025-02-18T05:16:16.518175Z"
        },
        "id": "0R2z_-FZU3qy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "assert 0.9 < accuracy < 0.91\n",
        "print(f\"Accuracy: {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KONQ1E0J-y6B"
      },
      "source": [
        "### Task 2: train the model (5 points)\n",
        "\n",
        "Fine-tune your own model. You are free to choose any model __except for the original BERT.__ We recommend [DeBERTa-v3](https://huggingface.co/microsoft/deberta-v3-base), but you can choose the best model based on public benchmarks (e.g. [GLUE](https://gluebenchmark.com/)).\n",
        "\n",
        "You can write the training code manually (as we did in class) or use transformers.Trainer (see [this example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification)). Please make sure that your model's accuracy is at least __comparable__ with the above example for BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-18T23:33:09.217494Z",
          "iopub.status.busy": "2025-02-18T23:33:09.217189Z",
          "iopub.status.idle": "2025-02-18T23:33:38.259309Z",
          "shell.execute_reply": "2025-02-18T23:33:38.258204Z",
          "shell.execute_reply.started": "2025-02-18T23:33:09.217466Z"
        },
        "id": "Sls1fB9DGxLB",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"microsoft/deberta-v3-base\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    hidden_dropout_prob=0.1,  # Restoring small dropout to reduce overfitting\n",
        "    attention_probs_dropout_prob=0.1\n",
        ")\n",
        "train_dataset = QQPDataset(qqp_preprocessed['train'])\n",
        "val_dataset = QQPDataset(qqp_preprocessed['validation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "T0ZkZTkl_yMU"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import EarlyStoppingCallback\n",
        "epoches = 6\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-6,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=6,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    weight_decay= 0.005,\n",
        "    push_to_hub=False,\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "def save_custom_checkpoint(trainer, epoch):\n",
        "    checkpoint_path = f\"./results/checkpoint-epoch-{epoch}\"\n",
        "    trainer.save_model(checkpoint_path)\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)],  # Stop after 1 bad epoch\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GhVwWPwSGxLC",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='113705' max='136446' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [113705/136446 2:59:15 < 35:51, 10.57 it/s, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.431800</td>\n",
              "      <td>0.457519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.309200</td>\n",
              "      <td>0.447268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.421900</td>\n",
              "      <td>0.422246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.493800</td>\n",
              "      <td>0.408628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.345600</td>\n",
              "      <td>0.417349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=113705, training_loss=0.4333482313447585, metrics={'train_runtime': 10755.4905, 'train_samples_per_second': 202.973, 'train_steps_per_second': 12.686, 'total_flos': 1.1966702736167424e+17, 'train_loss': 0.4333482313447585, 'epoch': 5.0})"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fad457d641f469e99bbe58a0f5a5b2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/1264 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8084\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            token_type_ids=batch['token_type_ids']\n",
        "        )\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        predictions = torch.argmax(probs, dim=1)\n",
        "        correct += (predictions == batch['labels']).sum().item()\n",
        "        total += batch['labels'].size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQD0IV44LrSs"
      },
      "source": [
        "### Task 3: try the full pipeline (2 point)\n",
        "\n",
        "Finally, it is time to use your model to find duplicate questions.\n",
        "Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n",
        "\n",
        "Showcase how your function works with at least 3 examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLSjmsKaUyQb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
